{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action performed:\n",
    "- PDFminer for pdf to txt conversion, for all input pdfs\n",
    "- From txt, description using nltk\n",
    "- summarization using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# processing imports\n",
    "import pandas as pd\n",
    "import summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils elements to move to utils after development\n",
    "\n",
    "def getListOfFiles(dirName):\n",
    "    '''\n",
    "        For the given path, get the List of all files in the directory tree \n",
    "    '''\n",
    "    paths = []\n",
    "    for path, subdirs, files in os.walk(dirName):\n",
    "        for name in files:\n",
    "            paths.append((Path(path+name)))            \n",
    "    return paths\n",
    "\n",
    "from pdfminer.pdfdocument import PDFDocument, PDFNoOutlines\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTPage, LTChar, LTAnno, LAParams, LTTextBox, LTTextLine\n",
    "\n",
    "class PDFPageDetailedAggregator(PDFPageAggregator):\n",
    "    def __init__(self, rsrcmgr, pageno=1, laparams=None):\n",
    "        PDFPageAggregator.__init__(self, rsrcmgr, pageno=pageno, laparams=laparams)\n",
    "        self.rows = []\n",
    "        self.page_number = 0\n",
    "    def receive_layout(self, ltpage):        \n",
    "        def render(item, page_number):\n",
    "            if isinstance(item, LTPage) or isinstance(item, LTTextBox):\n",
    "                for child in item:\n",
    "                    render(child, page_number)\n",
    "            elif isinstance(item, LTTextLine):\n",
    "                child_str = ''\n",
    "                for child in item:\n",
    "                    if isinstance(child, (LTChar, LTAnno)):\n",
    "                        child_str += child.get_text()\n",
    "                child_str = ' '.join(child_str.split()).strip()\n",
    "                if child_str:\n",
    "                    row = (page_number, item.bbox[0], item.bbox[1], item.bbox[2], item.bbox[3], child_str) # bbox == (x1, y1, x2, y2)\n",
    "                    self.rows.append(row)\n",
    "                for child in item:\n",
    "                    render(child, page_number)\n",
    "            return\n",
    "        render(ltpage, self.page_number)\n",
    "        self.page_number += 1\n",
    "        self.rows = sorted(self.rows, key = lambda x: (x[0], -x[2]))\n",
    "        self.result = ltpage\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "# TODO: deal with words cut in half \"pro- pagation of...\"\n",
    "def convert(input_file, pages_range):\n",
    "    \"\"\"\n",
    "    :param input_file: PDF filename\n",
    "    :param pages_range: (nb_first_page_rse:int, nb_last_page_rse:int), starting at 1\n",
    "    \"\"\"\n",
    "    fp = open(input_file, 'rb')\n",
    "    parser = PDFParser(fp)\n",
    "    doc = PDFDocument(parser)\n",
    "    # doc.initialize(\"passwrd\") # leave empty for no password\n",
    "\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    laparams = LAParams()\n",
    "    device = PDFPageDetailedAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    pages_selection = range(pages_range[0]-1,(pages_range[1]-1)+1)\n",
    "    for nb_page_parsed, page in enumerate(PDFPage.create_pages(doc)):\n",
    "        if nb_page_parsed in pages_selection:\n",
    "            interpreter.process_page(page)\n",
    "            # receive the LTPage object for this page\n",
    "            device.get_result()\n",
    "\n",
    "    # GROUPING\n",
    "    grouped_text = OrderedDict() # keep order is of identification in the document.\n",
    "    for (page_nb, x_min, y_min, x_max, y_max, text) in device.rows:\n",
    "        page_nb = (pages_range[0]) + page_nb # elsewise device starts again at 0\n",
    "        if page_nb not in grouped_text.keys():\n",
    "            grouped_text[page_nb] = {}\n",
    "        x_min = round(x_min)//10 # manipulate the level of aggregation,(unit?) --> x_min might be slighly adapted\n",
    "        try:\n",
    "            grouped_text[page_nb][x_min]+= \" \" + text # TODO: check if anomaly in paragraphe here\n",
    "        except:\n",
    "            grouped_text[page_nb][x_min] = text\n",
    "    \n",
    "    return grouped_text\n",
    "    \n",
    "###     KEEP for FUTURE  AGGREGATION\n",
    "#     # FULL TEXT BY PAGE\n",
    "#     text_by_page = OrderedDict()\n",
    "#     for key, values in grouped_text.items():\n",
    "#         if values:\n",
    "#             text_by_page[key] = \"\"\n",
    "#             for _, text in values.items():\n",
    "#                 text_by_page[key] += text + \" \"\n",
    "#     # FULL TEXT\n",
    "#     pdf_full_txt = \"\"\n",
    "#     for key, text in text_by_page.items():\n",
    "#         pdf_full_txt += text + \" \"\n",
    "        \n",
    "#     return (pdf_full_txt, text_by_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vinci': {'SIREN': 552037806,\n",
       "  'denomination': 'VINCI',\n",
       "  'rse_ranges': '(38,48)|(207,266)'},\n",
       " 'eiffage': {'SIREN': 709802094,\n",
       "  'denomination': 'Eiffage',\n",
       "  'rse_ranges': '(125,202)'},\n",
       " 'bouygues': {'SIREN': 397480930,\n",
       "  'denomination': 'Bouygues',\n",
       "  'rse_ranges': '(98,124)'},\n",
       " 'saintgobain': {'SIREN': 542039532,\n",
       "  'denomination': 'Saint-Gobain',\n",
       "  'rse_ranges': '(76,79)|(101,104)|(329,332)'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entreprises_filename = \"../../data/input/Entreprises/entreprises.csv\"\n",
    "df_entreprises = pd.read_csv(entreprises_filename, sep=\";\")\n",
    "pd.read_csv(entreprises_filename, sep=\";\").set_index(\"project_denomination\").T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/4 bouygues [bouygues_2018_ddr.pdf]\n",
      "Pages: 98 to 124\n",
      "Processing 1/4 eiffage [eiffage_2018_ddr.pdf]\n",
      "Pages: 125 to 202\n",
      "Processing 2/4 saintgobain [saintgobain_2018_ddr.pdf]\n",
      "Pages: 76 to 79\n",
      "Pages: 101 to 104\n",
      "Pages: 329 to 332\n",
      "Processing 3/4 vinci [vinci_2018_ddr.pdf]\n",
      "Pages: 38 to 48\n",
      "Pages: 207 to 266\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../../data/processed/DPEFs/dpef_paragraphs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0b8568a1772f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                                  \"paragraph\":paragraph}\n\u001b[0;32m     38\u001b[0m                     \u001b[0mdf_parsed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_parsed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_update\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mdf_parsed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\base_ml_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\base_ml_env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\base_ml_env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../../data/processed/DPEFs/dpef_paragraphs.csv'"
     ]
    }
   ],
   "source": [
    "# filepaths\n",
    "entreprises_filename = \"../../data/input/Entreprises/entreprises.csv\"\n",
    "input_path = \"../../data/input/DPEFs/Construction/\"\n",
    "output_filename= \"../../data/processed/DPEFs/dpef_paragraphs.csv\"\n",
    "\n",
    "# Entreprises : data\n",
    "dict_entreprises = pd.read_csv(entreprises_filename, sep=\";\").set_index(\"project_denomination\").T.to_dict()\n",
    "# Looks like 'vinci': {'SIREN': 552037806, 'denomination': 'VINCI'},\n",
    "\n",
    "# DPEF\n",
    "all_input_files = getListOfFiles(input_path)\n",
    "all_input_files = [p for p in all_input_files if p.name.lower().endswith(\".pdf\")]\n",
    "\n",
    "# output has shape...\n",
    "df_parsed_data = pd.DataFrame(columns = [\"SIREN\",\n",
    "                                         \"project_denomination\",\n",
    "                                         \"pdf_name\",\n",
    "                                         \"page_nb_in_pdf\",\n",
    "                                         \"paragraph_id\", # x_min for now\n",
    "                                         \"paragraph\"])\n",
    "for i, input_file in enumerate(all_input_files):\n",
    "    if input_file.name.endswith(\"pdf\"):\n",
    "        project_denomination = input_file.name.split(\"\\\\\")[-1].split(\"_\")[0] # first word of pdf name\n",
    "        print(\"Processing {}/{} {} [{}]\".format(i,len(all_input_files),project_denomination, input_file.name))\n",
    "        for rse_ranges in dict_entreprises[project_denomination][\"rse_ranges\"].split(\"|\"):\n",
    "            rse_ranges = eval(rse_ranges) # tuple format str to actual tuple\n",
    "            print(\"Pages: {} to {}\".format(rse_ranges[0], rse_ranges[1]))\n",
    "            grouped_text = convert(input_file, rse_ranges)\n",
    "            for page_nb, page_content in grouped_text.items():\n",
    "                for paragraph_id, paragraph in page_content.items():\n",
    "                    df_update = {\"SIREN\": dict_entreprises[project_denomination][\"SIREN\"],\n",
    "                                 \"denomination\": dict_entreprises[project_denomination][\"denomination\"],\n",
    "                                 \"project_denomination\": project_denomination,\n",
    "                                 \"pdf_name\": input_file.name.split(\"\\\\\")[-1],\n",
    "                                 \"page_nb_in_pdf\":page_nb,\n",
    "                                 \"paragraph_id\":paragraph_id,\n",
    "                                 \"paragraph\":paragraph}\n",
    "                    df_parsed_data = df_parsed_data.append(df_update, ignore_index=True)\n",
    "df_parsed_data.to_csv(output_filename,sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed_data.to_csv(output_filename,sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename= \"../../data/processed/DPEFs/dpef_paragraphs.csv\"\n",
    "df_parsed_data.to_csv(output_filename,sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed_data[df_parsed_data.project_denomination == \"bouygues\"][[\"paragraph_id\",\"paragraph\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leader français de la cogénération dans le maraîchage Eiffage Énergie Systèmes est le leader français de la cogénération dans le maraîchage, avec 116 installations en France pour 500 MWh électriques et 500 MWh thermiques installés.',\n",
       " 'Nouvelles mobilités et covoiturage Eiffage Énergie Systèmes est un moteur du développement des nouvelles mobilités, comme l’atteste le test dès janvier 2019 de la première navette autonome capable de circuler sur route ouverte en zone d’activités, baptisée Mia. Les équipes participent égale- ment au développement des réseaux de bornes de recharge élec- trique en milieu urbain comme sur autoroute.',\n",
       " 'Présentée le 27 novembre par Eiffage Énergie Systèmes et ses par- tenaires au salon Pollutec, le Salon des solutions environnementales pour l’industrie, la ville et les territoires, la navette autonome Mia a;Eiffage']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from summa.summarizer import summarize\n",
    "summa.summarizer.summarize(\"Des bâtiments performants énergétiquement, offrant une haute qualité d’usage à leurs habitants Eiffage Énergie Systèmes a présenté début mars 2018 son dispositif de supervision numérique énergétique des bâtiments publics, une première en Europe. Eiffage Énergie Systèmes réalise ainsi le système de supervision de la Ville de Paris. Les équipes de la branche sont chargées de la rénovation des installations techniques – instrumentation, compteurs, tableaux électriques, automates –, d’une partie des centres thermiques et de la mise en place d’un système de supervision pour l’ensemble du parc qui s’interfacera avec les outils de gestion interne existants. Afin d’affiner les données collectées, les équipes installent des cap- teurs intelligents sur les centres thermiques les plus importants et sont chargées du développement et de l’installation du logiciel pour organiser et mettre à disposition les données collectées. Par la collecte et l’exploitation de données via un réseau spécifique Internet des Objets (IoT), accompagnées d’une maintenance préventive et curative, ce dispositif favorisera une véritable démarche de management de l’énergie, et créera de nouveaux services et applications à destination des usagers. Par ailleurs, Eiffage Énergie Systèmes a signé en 2010 un contrat de performance énergétique (CPE) avec la région Centre, sur l’exploi- tation des installations énergétiques de 19 lycées durant quinze ans. L’entreprise s’est engagée à réaliser des économies d’énergie de l’ordre de 35 % et une réduction des gaz à effet de serre de 49 % d’ici à 2025. Leader français de la cogénération dans le maraîchage Eiffage Énergie Systèmes est le leader français de la cogénération dans le maraîchage, avec 116 installations en France pour 500 MWh électriques et 500 MWh thermiques installés. Ce procédé récupère le CO2 afin de favoriser la photosynthèse et produire de l’électricité, revendue par les maraîchers. La conception, l’installation et l’exploitation-maintenance de ces centrales de cogénération sont assurées par la branche et certifiées ISO 50001. Nouvelles mobilités et covoiturage Eiffage Énergie Systèmes est un moteur du développement des nouvelles mobilités, comme l’atteste le test dès janvier 2019 de la première navette autonome capable de circuler sur route ouverte en zone d’activités, baptisée Mia. Les équipes participent égale- ment au développement des réseaux de bornes de recharge élec- trique en milieu urbain comme sur autoroute. Présentée le 27 novembre par Eiffage Énergie Systèmes et ses par- tenaires au salon Pollutec, le Salon des solutions environnementales pour l’industrie, la ville et les territoires, la navette autonome Mia a;Eiffage\", \n",
    "                           words=100, \n",
    "                           split=True, \n",
    "                           language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547176"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_full_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
